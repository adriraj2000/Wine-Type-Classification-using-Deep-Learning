{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape - 82657,12\n",
    "#test.shape   - 20665,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.dropna(axis = 0)\n",
    "#test.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will be using the review description further as it is the main feature on which variety of grape depends as it gives information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Blend\n",
      "This wine is near equal parts Syrah and Merlot with the balance Cabernet Sauvignon. Aromas of blue fruit, vanilla, cherry and herb lead to full-bodied pit-fruit flavors that bring a sense of deliciousness that is hard to resist.\n",
      "\n",
      "Nebbiolo\n",
      "Barolo Conca opens with inky dark concentration and soothing aromas of black fruit, spice, cola, plum, prune and dried lavender buds. The nose presents those ethereal and delicate aromas, but in the mouth, it delivers thicker flavors of chocolate and mocha. Drink after 2018.\n",
      "\n",
      "Bordeaux-style White Blend\n",
      "It's impressive what a small addition of Sauvignon Gris and Muscadelle can do to a Sauvignon-Sémillon blend—it turns this into an exotic wine, with spice and lychee flavors.\n",
      "\n",
      "Malbec\n",
      "This ripe, sweet wine is rich and full of dried and fresh fruit flavors. It is spicy, with a touch of spirit on the palate as well as bold black-plum fruit, dense tannins and a sweet aftertaste. Drink from 2017.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print(train['variety'].iloc[i])\n",
    "    print(train['review_description'].iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(train['review_description'].min())-198\n",
    "#len(train['review_description'].max())-338\n",
    "#Keeping review description above 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 395  132   18 ...    0    0    0]\n",
      " [   7    9    8 ...    0    0    0]\n",
      " [1005    1  161 ...    0    0    0]\n",
      " ...\n",
      " [   7    8    4 ...    0    0    0]\n",
      " [  41  389    9 ...    0    0    0]\n",
      " [   4  179   40 ...    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(82657, 256)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of dictionary\n",
    "NUM_WORDS = 4000\n",
    "\n",
    "# Length of each review\n",
    "SEQ_LEN = 256\n",
    "\n",
    "#create tokenizer for our data\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=NUM_WORDS, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(train['review_description'])\n",
    "\n",
    "#convert text data to numerical indexes\n",
    "wine_seqs=tokenizer.texts_to_sequences(train['review_description'])\n",
    "\n",
    "#pad data up to SEQ_LEN (note that we truncate if there are more than SEQ_LEN tokens)\n",
    "wine_seqs=tf.keras.preprocessing.sequence.pad_sequences(wine_seqs, maxlen=SEQ_LEN, padding=\"post\")\n",
    "\n",
    "print(wine_seqs)\n",
    "wine_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pinot_noir': 1, 'chardonnay': 2, 'cabernet_sauvignon': 3, 'red_blend': 4, 'bordeaux-style_red_blend': 5, 'riesling': 6, 'sauvignon_blanc': 7, 'syrah': 8, 'rosé': 9, 'merlot': 10, 'nebbiolo': 11, 'zinfandel': 12, 'sangiovese': 13, 'malbec': 14, 'portuguese_red': 15, 'white_blend': 16, 'sparkling_blend': 17, 'tempranillo': 18, 'rhône-style_red_blend': 19, 'pinot_gris': 20, 'champagne_blend': 21, 'cabernet_franc': 22, 'grüner_veltliner': 23, 'portuguese_white': 24, 'pinot_grigio': 25, 'bordeaux-style_white_blend': 26, 'gewürztraminer': 27, 'gamay': 28}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(82657, 1)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_labels=pd.DataFrame({'variety': train['variety']})\n",
    "wine_labels=wine_labels.replace(' ', '_', regex=True)\n",
    "\n",
    "wine_labels_list = []\n",
    "for item in wine_labels['variety']:\n",
    "    wine_labels_list.append(str(item))\n",
    "\n",
    "label_tokenizer = tf.keras.preprocessing.text.Tokenizer(split=' ', filters='!\"#$%&()*+,./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "label_tokenizer.fit_on_texts(wine_labels_list)\n",
    "\n",
    "print(label_tokenizer.word_index)\n",
    "\n",
    "wine_label_seq = np.array(label_tokenizer.texts_to_sequences(wine_labels_list))\n",
    "wine_label_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:(66125, 256) y_train:(66125, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(wine_seqs,\n",
    "                                                    wine_label_seq,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=42)\n",
    "print('X_train:{} y_train:{}'.format(X_train.shape,y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will be using Keras Sequential Model which is a stacked layer of neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 256)         1024000   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, None, 128)         163968    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 29)                1885      \n",
      "=================================================================\n",
      "Total params: 1,198,109\n",
      "Trainable params: 1,198,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 256\n",
    "EMBEDDING_SIZE_2 = 64\n",
    "EMBEDDING_SIZE_3 = 29 #28+1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(NUM_WORDS, EMBEDDING_SIZE),\n",
    "    tf.keras.layers.Conv1D(128,5,activation='relu'), \n",
    "    tf.keras.layers.GlobalMaxPooling1D(), \n",
    "    tf.keras.layers.Dense(EMBEDDING_SIZE_2, activation='relu'),\n",
    "    # Add a Dense layer with additional units and softmax activation.\n",
    "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
    "    tf.keras.layers.Dense(EMBEDDING_SIZE_3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2067/2067 - 441s - loss: 1.3897 - accuracy: 0.5837 - val_loss: 1.0490 - val_accuracy: 0.6786\n",
      "Epoch 2/3\n",
      "2067/2067 - 395s - loss: 0.8682 - accuracy: 0.7293 - val_loss: 0.9977 - val_accuracy: 0.6963\n",
      "Epoch 3/3\n",
      "2067/2067 - 340s - loss: 0.6392 - accuracy: 0.7993 - val_loss: 1.0566 - val_accuracy: 0.6939\n",
      "517/517 [==============================] - 21s 41ms/step - loss: 1.0566 - accuracy: 0.6939\n",
      "Loss:  1.0566279888153076\n",
      "Accuracy:  0.6938664317131042\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "history = model.fit(X_train,y_train, epochs=num_epochs, validation_data=(X_val,y_val), verbose=2)\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = [test['review_description'][12]]\n",
    "encoded_sample_pred_text = tokenizer.texts_to_sequences(new_review)\n",
    "encoded_sample_pred_text = tf.keras.preprocessing.sequence.pad_sequences(encoded_sample_pred_text, maxlen=SEQ_LEN, padding=\"post\")\n",
    "predictions = model.predict(encoded_sample_pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess: rosé \n",
      " Probability: 89.178485%\n"
     ]
    }
   ],
   "source": [
    "reverse_label_index = dict([(value, key) for (key, value) in label_tokenizer.word_index.items()])\n",
    "\n",
    "def decode_label(text):\n",
    "    return ' '.join([reverse_label_index.get(i, 'Unknown') for i in text])\n",
    "for n in reversed((np.argsort(predictions))[0]):\n",
    "    predicted_id = [n]\n",
    "    print(\"Guess: %s \\n Probability: %f\" %(decode_label(predicted_id).replace('_', ' '), 100*predictions[0][predicted_id][0]) + '%')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test['review_description']\n",
    "encoded_sample_pred_text = tokenizer.texts_to_sequences(X_test)\n",
    "encoded_sample_pred_text = tf.keras.preprocessing.sequence.pad_sequences(encoded_sample_pred_text, maxlen=SEQ_LEN, padding=\"post\")\n",
    "y_pred = model.predict(encoded_sample_pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for n in reversed((np.argsort(y_pred))[0]):\n",
    "    predicted_id = [n]\n",
    "    y.append(decode_label(predicted_id).replace('_',' '))\n",
    "y_pred = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pinot noir', 'sangiovese', 'gamay', 'cabernet franc', 'red blend',\n",
       "       'nebbiolo', 'pinot gris', 'zinfandel', 'bordeaux-style red blend',\n",
       "       'merlot', 'rosé', 'tempranillo', 'sparkling blend',\n",
       "       'rhône-style red blend', 'champagne blend', 'malbec',\n",
       "       'portuguese red', 'cabernet sauvignon', 'syrah', 'pinot grigio',\n",
       "       'gewürztraminer', 'white blend', 'chardonnay', 'riesling',\n",
       "       'sauvignon blanc', 'grüner veltliner', 'portuguese white',\n",
       "       'bordeaux-style white blend', 'Unknown'], dtype='<U26')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred)\n",
    "df.columns=['variety']\n",
    "\n",
    "pred = pd.concat([test, df], axis = 1)\n",
    "\n",
    "pred.index=pred.user_name\n",
    "pred=pred[['variety']]\n",
    "\n",
    "pred.to_csv('prediction.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
